{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a297ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5255b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. The dog was sleeping under a tree. \n",
    "A tree provides shade on a sunny day. The day was bright and beautiful. \n",
    "Beautiful flowers bloom in the spring. Spring brings new life to the garden. \n",
    "The garden has many colorful plants. Plants need water and sunlight to grow. \n",
    "To grow strong, they require proper care. Proper care includes regular watering. \n",
    "Watering should be done in the morning. The morning sun is gentle and warm. \n",
    "Warm weather makes people happy. Happy children play in the park. \n",
    "The park is full of laughter and joy. Joy spreads when friends are together. \n",
    "Together they explore new adventures. Adventures make life exciting and fun. \n",
    "Fun times create lasting memories. Memories are treasures we keep forever.\n",
    "\n",
    "Machine learning is a powerful tool for solving complex problems. Complex problems require innovative solutions.\n",
    "Solutions often come from careful analysis of data. Data is the foundation of modern artificial intelligence.\n",
    "Artificial intelligence is transforming industries across the world. The world is becoming more connected every day.\n",
    "Every day brings new opportunities to learn. Learning is a lifelong journey of discovery.\n",
    "Discovery leads to innovation and progress. Progress requires dedication and hard work.\n",
    "Hard work pays off in the long run. The long run requires patience and persistence.\n",
    "\n",
    "Python is a popular programming language for data science. Data science involves analyzing large datasets.\n",
    "Large datasets contain valuable insights and patterns. Patterns help us understand complex phenomena.\n",
    "Complex phenomena can be modeled using neural networks. Neural networks learn from examples and experience.\n",
    "Experience teaches us important lessons about life. Life is full of challenges and opportunities.\n",
    "Opportunities arise when we least expect them. We must be prepared to seize the moment.\n",
    "The moment we decide to act determines our future. Our future depends on the choices we make today.\n",
    "\n",
    "Technology is rapidly evolving in the modern era. The modern era is characterized by digital transformation.\n",
    "Digital transformation is changing how businesses operate. Businesses must adapt to stay competitive in the market.\n",
    "The market demands innovation and efficiency. Efficiency can be improved through automation and optimization.\n",
    "Optimization techniques help maximize performance and results. Results are what matter most in business.\n",
    "Business success requires strategic planning and execution. Execution is where ideas become reality.\n",
    "Reality often differs from our expectations. Expectations should be based on realistic assumptions.\n",
    "\n",
    "Education is the key to personal growth. Personal growth requires self-reflection and improvement.\n",
    "Improvement comes from learning new skills and knowledge. Knowledge is power in the information age.\n",
    "The information age has revolutionized communication. Communication is essential for human connection.\n",
    "Human connection brings meaning to our lives. Our lives are shaped by the relationships we build.\n",
    "We build relationships through trust and respect. Respect is earned through consistent actions.\n",
    "Actions speak louder than words in all situations. All situations require careful consideration before acting.\n",
    "\n",
    "Nature is a source of inspiration and wonder. Wonder fills us with curiosity about the universe.\n",
    "The universe is vast and full of mysteries. Mysteries challenge us to think deeply.\n",
    "Thinking deeply helps us understand ourselves better. Understanding ourselves is the first step to wisdom.\n",
    "Wisdom comes from experience and reflection. Reflection allows us to learn from our mistakes.\n",
    "Our mistakes are valuable teachers in life. Life teaches us lessons through both success and failure.\n",
    "Failure is not the opposite of success. Success is built on a foundation of failures.\n",
    "\n",
    "The ocean is home to countless species of marine life. Marine life includes fish, whales, and dolphins.\n",
    "Dolphins are intelligent and social creatures. Creatures in the ocean have adapted to their environment.\n",
    "Their environment is constantly changing and dynamic. Dynamic systems require continuous monitoring and adjustment.\n",
    "Adjustment is necessary when conditions change. Change is the only constant in life.\n",
    "In life, we must learn to embrace uncertainty. Uncertainty can be uncomfortable but also exciting.\n",
    "Exciting opportunities often come with some risk. Risk management is important in decision making.\n",
    "\n",
    "Books are windows into different worlds and perspectives. Perspectives shape how we see reality.\n",
    "Reality is subjective and depends on individual experience. Individual experience varies from person to person.\n",
    "From person to person, we can learn valuable lessons. Lessons learned help us grow wiser.\n",
    "Wiser people make better decisions overall. Overall, wisdom improves quality of life.\n",
    "Quality of life depends on many factors. Factors include health, relationships, and purpose.\n",
    "Purpose gives meaning to our daily activities. Activities should align with our core values.\n",
    "\n",
    "Music has the power to evoke strong emotions. Emotions influence our thoughts and behaviors.\n",
    "Behaviors can be changed through conscious effort. Effort is required to achieve any goal.\n",
    "Any goal worth pursuing takes time to accomplish. To accomplish great things requires perseverance.\n",
    "Perseverance is the ability to keep going. Keep going even when times are tough.\n",
    "Tough times don't last but tough people do. People who persist eventually reach their destination.\n",
    "Their destination may be different than originally planned. Originally planned paths sometimes need adjustment.\n",
    "\n",
    "Exercise is important for maintaining good health. Good health contributes to overall wellbeing.\n",
    "Wellbeing encompasses physical, mental, and emotional health. Mental health is just as important as physical health.\n",
    "Physical health can be improved through regular activity. Regular activity includes walking, running, and swimming.\n",
    "Swimming is a low-impact form of exercise. Exercise releases endorphins that improve mood.\n",
    "Mood affects how we perceive the world. The world looks different depending on our state of mind.\n",
    "Our state of mind can be influenced by thoughts. Thoughts have power to shape our reality.\n",
    "\n",
    "Dreams inspire us to reach for something greater. Something greater than ourselves gives life purpose.\n",
    "Life purpose drives us forward each day. Each day is a new opportunity to grow.\n",
    "To grow requires stepping outside comfort zones. Comfort zones limit our potential for development.\n",
    "Development happens when we challenge ourselves. Ourselves and our capabilities are often underestimated.\n",
    "Underestimated people can surprise everyone around them. Around them, others begin to see new possibilities.\n",
    "New possibilities emerge when we think creatively. Creatively solving problems leads to innovation.\n",
    "\n",
    "Food brings people together across cultures. Across cultures, certain values remain universal.\n",
    "Universal values include love, kindness, and compassion. Compassion helps us connect with others.\n",
    "Others benefit when we show empathy and understanding. Understanding different viewpoints enriches our perspective.\n",
    "Our perspective broadens through travel and exploration. Exploration satisfies our innate curiosity about the world.\n",
    "The world offers endless opportunities for adventure. Adventure awaits those who dare to seek it.\n",
    "To seek new experiences requires courage and openness. Openness to new ideas fosters personal growth.\n",
    "\n",
    "Time is our most valuable resource. Resources should be used wisely and efficiently.\n",
    "Efficiently managing time leads to greater productivity. Productivity increases when we focus on priorities.\n",
    "Priorities should reflect our deepest values. Values guide our decisions and actions.\n",
    "Actions create the life we want to live. To live fully means embracing each moment.\n",
    "Each moment is precious and unrepeatable. Unrepeatable experiences make life memorable and rich.\n",
    "Rich experiences come from genuine connections with others. Others help us see ourselves more clearly.\n",
    "\n",
    "Creativity flourishes when we give ourselves permission to experiment. To experiment means accepting the possibility of failure.\n",
    "Failure provides feedback for improvement and learning. Learning from mistakes accelerates progress significantly.\n",
    "Significantly better outcomes result from continuous refinement. Refinement is an iterative process of improvement.\n",
    "Improvement never ends for those committed to excellence. Excellence is achieved through dedication and practice.\n",
    "Practice makes progress, not necessarily perfection. Perfection is an ideal that inspires us forward.\n",
    "Forward movement is what matters most in the journey. The journey itself is more important than the destination.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aae87a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(document.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c508512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n"
     ]
    }
   ],
   "source": [
    "vocab = {'<UNK>':0}\n",
    "\n",
    "for token in Counter(tokens).keys():\n",
    "    if token not in vocab:\n",
    "        vocab[token]=len(vocab)\n",
    "        \n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fcfbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = document.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "930b43d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(sentence, vocab):\n",
    "    # tokens = word_tokenize(text)\n",
    "    result = []\n",
    "    for token in sentence:\n",
    "        if token in vocab:\n",
    "            result.append(vocab[token])\n",
    "        else:\n",
    "            result.append(vocab['<UNK>'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ddde4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numerical_sentences = []\n",
    "for sentence in input_sentences:\n",
    "    input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()),vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "341ab4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequence = []\n",
    "for sentence in input_numerical_sentences:\n",
    "    for i in range(1,len(sentence)):\n",
    "        training_sequence.append(sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "999ca616",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for sentence in training_sequence:\n",
    "    len_list.append(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7c57e465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4223c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_training_sequence = []\n",
    "for sequence in training_sequence:\n",
    "    padded_training_sequence.append([0]*(21-len(sequence))+sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9238860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_training_sequence = torch.tensor(padded_training_sequence,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dabea94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
       "        [  0,   0,   0,  ...,   1,   2,   3],\n",
       "        [  0,   0,   0,  ...,   2,   3,   4],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ..., 157, 249,   1],\n",
       "        [  0,   0, 423,  ..., 249,   1, 383],\n",
       "        [  0, 423, 527,  ...,   1, 383,   9]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_training_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76f39af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_training_sequence[:,:-1]\n",
    "y = padded_training_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e6e773e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
       "        [  0,   0,   0,  ...,   0,   1,   2],\n",
       "        [  0,   0,   0,  ...,   1,   2,   3],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ..., 111, 157, 249],\n",
       "        [  0,   0, 423,  ..., 157, 249,   1],\n",
       "        [  0, 423, 527,  ..., 249,   1, 383]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "207c95f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2,   3,   4,  ...,   1, 383,   9])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d326ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index],self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5a0e7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8241929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de5ff07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " tensor(2))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cc760e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0224e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,100)\n",
    "        self.lstm = nn.LSTM(100,150,batch_first=True)\n",
    "        self.fc = nn.Linear(150,vocab_size)\n",
    "    def forward(self,x):\n",
    "        embedded = self.embedding(x)\n",
    "        intermediate_hidden_states,(final_hidden_state,final_cell_state) = self.lstm(embedded)\n",
    "        output = self.fc(final_hidden_state).squeeze(0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "08fb2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "612ee526",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a5a4c437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(530, 100)\n",
       "  (lstm): LSTM(100, 150, batch_first=True)\n",
       "  (fc): Linear(in_features=150, out_features=530, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3c93c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9cb16310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Avg Loss: 15.357909146477194\n",
      "Epoch: 2, Avg Loss: 13.38002908931059\n",
      "Epoch: 3, Avg Loss: 12.424948692321777\n",
      "Epoch: 4, Avg Loss: 11.452746798010434\n",
      "Epoch: 3, Avg Loss: 12.424948692321777\n",
      "Epoch: 4, Avg Loss: 11.452746798010434\n",
      "Epoch: 5, Avg Loss: 10.435917728087482\n",
      "Epoch: 6, Avg Loss: 9.366511302835802\n",
      "Epoch: 5, Avg Loss: 10.435917728087482\n",
      "Epoch: 6, Avg Loss: 9.366511302835802\n",
      "Epoch: 7, Avg Loss: 8.32980843151317\n",
      "Epoch: 8, Avg Loss: 7.383516269571641\n",
      "Epoch: 7, Avg Loss: 8.32980843151317\n",
      "Epoch: 8, Avg Loss: 7.383516269571641\n",
      "Epoch: 9, Avg Loss: 6.432085850659539\n",
      "Epoch: 10, Avg Loss: 5.559761292794171\n",
      "Epoch: 9, Avg Loss: 6.432085850659539\n",
      "Epoch: 10, Avg Loss: 5.559761292794171\n",
      "Epoch: 11, Avg Loss: 4.754843333188226\n",
      "Epoch: 12, Avg Loss: 4.048045018140008\n",
      "Epoch: 11, Avg Loss: 4.754843333188226\n",
      "Epoch: 12, Avg Loss: 4.048045018140008\n",
      "Epoch: 13, Avg Loss: 3.426171429017011\n",
      "Epoch: 14, Avg Loss: 2.8928027433507584\n",
      "Epoch: 13, Avg Loss: 3.426171429017011\n",
      "Epoch: 14, Avg Loss: 2.8928027433507584\n",
      "Epoch: 15, Avg Loss: 2.4126189210835625\n",
      "Epoch: 16, Avg Loss: 2.0534677750924053\n",
      "Epoch: 15, Avg Loss: 2.4126189210835625\n",
      "Epoch: 16, Avg Loss: 2.0534677750924053\n",
      "Epoch: 17, Avg Loss: 1.7349201440811157\n",
      "Epoch: 18, Avg Loss: 1.4680981215308695\n",
      "Epoch: 17, Avg Loss: 1.7349201440811157\n",
      "Epoch: 18, Avg Loss: 1.4680981215308695\n",
      "Epoch: 19, Avg Loss: 1.2540977474521189\n",
      "Epoch: 20, Avg Loss: 1.0853473351282232\n",
      "Epoch: 19, Avg Loss: 1.2540977474521189\n",
      "Epoch: 20, Avg Loss: 1.0853473351282232\n",
      "Epoch: 21, Avg Loss: 0.9438902122132918\n",
      "Epoch: 22, Avg Loss: 0.8272982721819597\n",
      "Epoch: 21, Avg Loss: 0.9438902122132918\n",
      "Epoch: 22, Avg Loss: 0.8272982721819597\n",
      "Epoch: 23, Avg Loss: 0.7325417995452881\n",
      "Epoch: 24, Avg Loss: 0.6540049796595293\n",
      "Epoch: 23, Avg Loss: 0.7325417995452881\n",
      "Epoch: 24, Avg Loss: 0.6540049796595293\n",
      "Epoch: 25, Avg Loss: 0.5863529478802401\n",
      "Epoch: 26, Avg Loss: 0.5343879049315172\n",
      "Epoch: 25, Avg Loss: 0.5863529478802401\n",
      "Epoch: 26, Avg Loss: 0.5343879049315172\n",
      "Epoch: 27, Avg Loss: 0.48599306581651464\n",
      "Epoch: 28, Avg Loss: 0.44388817995786667\n",
      "Epoch: 27, Avg Loss: 0.48599306581651464\n",
      "Epoch: 28, Avg Loss: 0.44388817995786667\n",
      "Epoch: 29, Avg Loss: 0.4121091628775877\n",
      "Epoch: 30, Avg Loss: 0.3776788343401516\n",
      "Epoch: 29, Avg Loss: 0.4121091628775877\n",
      "Epoch: 30, Avg Loss: 0.3776788343401516\n",
      "Epoch: 31, Avg Loss: 0.3520253787145895\n",
      "Epoch: 32, Avg Loss: 0.33127549378310933\n",
      "Epoch: 31, Avg Loss: 0.3520253787145895\n",
      "Epoch: 32, Avg Loss: 0.33127549378310933\n",
      "Epoch: 33, Avg Loss: 0.31006548991974664\n",
      "Epoch: 34, Avg Loss: 0.2942574523827609\n",
      "Epoch: 33, Avg Loss: 0.31006548991974664\n",
      "Epoch: 34, Avg Loss: 0.2942574523827609\n",
      "Epoch: 35, Avg Loss: 0.27662066589383516\n",
      "Epoch: 36, Avg Loss: 0.26416073104037957\n",
      "Epoch: 35, Avg Loss: 0.27662066589383516\n",
      "Epoch: 36, Avg Loss: 0.26416073104037957\n",
      "Epoch: 37, Avg Loss: 0.2517718837103423\n",
      "Epoch: 38, Avg Loss: 0.23833575910505125\n",
      "Epoch: 37, Avg Loss: 0.2517718837103423\n",
      "Epoch: 38, Avg Loss: 0.23833575910505125\n",
      "Epoch: 39, Avg Loss: 0.23049122599117897\n",
      "Epoch: 40, Avg Loss: 0.21884938022669623\n",
      "Epoch: 39, Avg Loss: 0.23049122599117897\n",
      "Epoch: 40, Avg Loss: 0.21884938022669623\n",
      "Epoch: 41, Avg Loss: 0.209116978899521\n",
      "Epoch: 42, Avg Loss: 0.20334762838833473\n",
      "Epoch: 41, Avg Loss: 0.209116978899521\n",
      "Epoch: 42, Avg Loss: 0.20334762838833473\n",
      "Epoch: 43, Avg Loss: 0.2008589598185876\n",
      "Epoch: 44, Avg Loss: 0.19426804715219667\n",
      "Epoch: 43, Avg Loss: 0.2008589598185876\n",
      "Epoch: 44, Avg Loss: 0.19426804715219667\n",
      "Epoch: 45, Avg Loss: 0.1841641852960867\n",
      "Epoch: 46, Avg Loss: 0.17750042983714273\n",
      "Epoch: 45, Avg Loss: 0.1841641852960867\n",
      "Epoch: 46, Avg Loss: 0.17750042983714273\n",
      "Epoch: 47, Avg Loss: 0.17540878408095417\n",
      "Epoch: 48, Avg Loss: 0.17002010980949683\n",
      "Epoch: 47, Avg Loss: 0.17540878408095417\n",
      "Epoch: 48, Avg Loss: 0.17002010980949683\n",
      "Epoch: 49, Avg Loss: 0.16275958716869354\n",
      "Epoch: 50, Avg Loss: 0.15765637334655314\n",
      "Epoch: 49, Avg Loss: 0.16275958716869354\n",
      "Epoch: 50, Avg Loss: 0.15765637334655314\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x,batch_y = batch_x.to(device),batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_x)\n",
    "        \n",
    "        loss = criterion(output,batch_y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "    print(f\"Epoch: {epoch+1}, Avg Loss: {total_loss/len(batch_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68670394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,vocab, text):\n",
    "    \n",
    "    tokenized_text = word_tokenize(text.lower())\n",
    "    \n",
    "    numerical_text = text_to_indices(tokenized_text,vocab)\n",
    "    \n",
    "    padded_text = torch.tensor([0]*(21-len(numerical_text)) + numerical_text,dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    padded_text = padded_text.to(device)  # Move tensor to GPU\n",
    "    \n",
    "    output = model(padded_text)\n",
    "    \n",
    "    value,index = torch.max(output, dim=1)\n",
    "    \n",
    "    return text+ \" \"+list(vocab.keys())[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0ef17d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A tree provides shade'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, vocab,'A tree provides')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "de4be1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi has\n",
      "Hi has the\n",
      "Hi has the power\n",
      "Hi has the power to\n",
      "Hi has the power to evoke\n",
      "Hi has the power to evoke strong\n",
      "Hi has the power to evoke strong emotions\n",
      "Hi has the power to evoke strong emotions .\n",
      "Hi has the power to evoke strong emotions . emotions\n",
      "Hi has the power to evoke strong emotions . emotions influence\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 10\n",
    "input_text = 'Hi'\n",
    "for i in range(num_tokens):\n",
    "    output = predict(model,vocab,input_text)\n",
    "    print(output)\n",
    "    input_text=output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
